{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b69374f-22e6-437e-b969-ccf91179823c",
   "metadata": {},
   "source": [
    "## Dia 5 (Repaso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1eee7-5cf5-479d-ae90-d60406f0b6fb",
   "metadata": {},
   "source": [
    "## Creación de puntos aleatorios y joins con Geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db196444-c8d1-4de7-a3fd-5ea17e83e763",
   "metadata": {},
   "source": [
    "Antes de nada recordar que un join es una unión entre dos tablas (o shapes) basado en un campo en común, con lo cual nos permite traer elementos de una tabla/shape a otro.\n",
    "\n",
    "\n",
    "Esto es una combinación de lo visto los días 2 y 3. Abrimos el shape de fincas con geopandas y usamos el método sample_points cerar puntos aleatorios en cada polígono \n",
    "\n",
    "¿Podríamos usar el área del polígono para determinar el número de puntos a crear para que fueran más representativos?\n",
    "\n",
    "Para ver los joins, vamos a seguir la estrategia que vimos en clase partiendo las fincas según la Titularidad Pública o Privada.\n",
    "\n",
    "Luego cruzamos los shapes de puntos aleatorios con el ndvi (o el dtm, o el raster que queramos). Una vez que tenemos los puntos vamos a ver que tenemos un problema y es que \n",
    "\n",
    "\n",
    "Una vez que tenemos las capas de puntos las volvemos a juntar... (es muy ridículo, pero es solo un ejemplo). En realidad en nuestro caso no se trataría de un join como tal (o sí, podríamos hacer dos join, uno para cada tipo de finca), sino tan solo una concatenación (igual que haríamos con Numpy). La cuestión en cuaqluier caso es que no nos guarda ningún campo del shape original con el que podríamos hacer luego el join.  Así que la mejor solución es hacer un Spatial Join, que es un join basado en las geometrías (en nuestro caso los puntos que caen dentro de cada finca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8104518-cb7d-4803-b3ee-fdb0d797f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Abrimos el shape\n",
    "fp = \"/home/diego/git/AEPython_2024/data/fincas_ETRS89.shp\"\n",
    "data = gpd.read_file(fp)\n",
    "\n",
    "# Arreglamos los nombres de las columnas (innecesario para el ejercicio)\n",
    "colnames = {'FINCA':'FINCAS', 'TITULARIDA':'TITULARIDAD'}\n",
    "data.rename(columns=colnames, inplace=True)\n",
    "\n",
    "#Subset de dos nuevos gdfs con las fincas privadas y fincas publicas\n",
    "privada = data[data['TITULARIDAD'] == 'Privada']\n",
    "publica = data[data['TITULARIDAD'] == 'Pública']\n",
    "\n",
    "#Creamos los puntos\n",
    "pts_privadas = privada.sample_points(25)\n",
    "pts_publicas = public.sample_points(25)\n",
    "\n",
    "#Guardamos las fincas a shapefile\n",
    "pts_privadas.to_file('/home/diego/git/AEPython_2024/data/fprivadas_rpoints.shp')\n",
    "pts_publicas.to_file('/home/diego/git/AEPython_2024/data/fpublicas_rpoints.shp')\n",
    "\n",
    "# Cargar los puntos generados y los polígonos (fincas)\n",
    "\n",
    "# ¿Es esto necesario o nos valdría con las variables pts_privadas o pts_publicas y data ya abiertas?\n",
    "points_gdf = gpd.read_file('/home/diego/git/AEPython_2024/data/fprivadas_rpoints.shp')\n",
    "polygons_gdf = gpd.read_file('/home/diego/git/AEPython_2024/data/fincas_ETRS89.shp')\n",
    "\n",
    "# Comprobamos que tienen el mismo CRS puntos y polígonos\n",
    "print(points_gdf.crs)  # CRS de los puntos\n",
    "print(polygons_gdf.crs)  # CRS de los polígonos\"\"\"\n",
    "\n",
    "# Hacer el join utilizando el campo \"id\" (Join by Attributes)\n",
    "# Así haríamos el Join por atributos (vemos que es básicamente lenguaje SQL para hacer uniones de tablas\n",
    "publicas_attr = points_gdf.merge(data[['OBJECTID', 'FINCA']], left_on='FID', right_on='OBJECTID')\n",
    "\n",
    "# Spatial Join (el más chulo)\n",
    "# Cargar puntos generados y el shapefile de polígonos\n",
    "points_gdf = gpd.read_file('/home/diego/git/AEPython_2024/data/fprivadas_rpoints.shp') # Hay que hacer los dos shapes de puntos\n",
    "polygons_gdf = gpd.read_file('/home/diego/git/AEPython_2024/data/fincas_ETRS89.shp')\n",
    "\n",
    "# Realizar el spatial join\n",
    "points_with_attributes = gpd.sjoin(points_gdf, polygons_gdf[['OBJECTID', 'FINCA', 'geometry']], how='left', predicate='within')\n",
    "\n",
    "# Guardar los puntos con los atributos\n",
    "points_with_attributes.to_file('/home/diego/git/AEPython_2024/data/fprivadas_rpoints_attr_sj.shp')\n",
    "\n",
    "# Ver el resultado\n",
    "#print(points_with_attributes.head())\n",
    "\n",
    "# Cargar los dos shapefiles\n",
    "gdf1 = gpd.read_file('/home/diego/git/AEPython_2024/data/fpublicas_rpoints_attr_sj.shp')\n",
    "gdf2 = gpd.read_file('/home/diego/git/AEPython_2024/data/fprivadas_rpoints_attr_sj.shp')\n",
    "\n",
    "# Concatenar los dos GeoDataFrames\n",
    "# Aquí no es un join, sino que estamos juntando dos shapes en un único shape, tan solo hay que concatenar los GDFs\n",
    "combined_gdf = gpd.GeoDataFrame(pd.concat([gdf1, gdf2], ignore_index=True))\n",
    "\n",
    "# Verificar que tienen el mismo CRS (si no, reproyectar)\n",
    "if gdf1.crs != gdf2.crs:\n",
    "    gdf2 = gdf2.to_crs(gdf1.crs)\n",
    "\n",
    "# Guardar el resultado en un nuevo shapefile que contenga todos los puntos\n",
    "combined_gdf.to_file('/home/diego/git/AEPython_2024/data/fmerged_rpoints_attr_sj.shp')\n",
    "\n",
    "# Ver el resultado\n",
    "#print(combined_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f01523-70b0-43b3-8012-b50541b1b7dd",
   "metadata": {},
   "source": [
    "## Cruce de los puntos aleatorios dentro de los polígonos de las fncas del END con el NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf572b-f9f7-413b-867e-285379b43028",
   "metadata": {},
   "source": [
    "Usamos los NDVI y Puntos ya creados y usamos el script que vimos en la clase para trabajar con los geometrías de tipo Multipoint (de hecho, en un primer momento nos fallo por eso). Una vez que tenemos todos los puntos de cada polígono que se almacenan en la lista point_values, calculamos su promedio y ese es el valor que vamos a guardar en el shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604fa34-3a93-486c-891c-cf8bf9693fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "## Necesitamos crear dos archivos con puntos aleatorios dentro de cada finca\n",
    "\n",
    "# Cargar el archivo de puntos (shapefile)\n",
    "shapefile_path = '/home/diego/git/AEPython_2024/data/fmerged_rpoints_attr_sj.shp'\n",
    "points_gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Cargar el archivo ráster\n",
    "# raster_path = 'path_to_your_raster.tif'\n",
    "raster = rasterio.open('/home/diego/git/AEPython_2024/data/ndvi_.tif')\n",
    "\n",
    "# Crear una lista para almacenar los valores de los puntos\n",
    "values = []\n",
    "\n",
    "# Iterar sobre cada geometría en el shapefile\n",
    "for geom in points_gdf.geometry:\n",
    "    # Lista para almacenar valores de puntos individuales\n",
    "    point_values = []\n",
    "\n",
    "    if geom.geom_type == 'Point':\n",
    "        # Si es un solo punto, extraer las coordenadas\n",
    "        coords = (geom.x, geom.y)\n",
    "        # Obtener el índice de la fila/columna correspondiente a las coordenadas del punto\n",
    "        row, col = raster.index(coords[0], coords[1])\n",
    "        # Extraer el valor del ráster en esa posición\n",
    "        point_values.append(raster.read(1)[row, col])\n",
    "\n",
    "    elif geom.geom_type == 'MultiPoint':\n",
    "        # Si es MultiPoint, iterar sobre todos los puntos\n",
    "        for point in geom.geoms:\n",
    "            coords = (point.x, point.y)\n",
    "            row, col = raster.index(coords[0], coords[1])\n",
    "            # Extraer el valor del ráster en esa posición\n",
    "            point_values.append(raster.read(1)[row, col])\n",
    "\n",
    "    # Calcular el valor medio si hay puntos válidos, si no asignar None\n",
    "    if point_values:\n",
    "        mean_value = sum(point_values) / len(point_values)\n",
    "        values.append(mean_value)\n",
    "    else:\n",
    "        values.append(None)\n",
    "\n",
    "# Añadir los valores obtenidos al GeoDataFrame\n",
    "points_gdf['raster_value'] = values\n",
    "\n",
    "# Mostrar los valores obtenidos\n",
    "print(points_gdf[['geometry', 'raster_value']])\n",
    "\n",
    "# Guardamos el gdf a un nuevo shapefile\n",
    "points_gdf.to_file('/home/diego/git/AEPython_2024/data/fmerged_rpoints_attr_sj_ndvi.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d5ae3-fe06-45e2-b24f-2d7233aae2de",
   "metadata": {},
   "source": [
    "## Sample points Multibanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334e360-83d9-495b-af05-ef6425317a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Cargar el archivo de puntos (shapefile)\n",
    "shapefile_path = '/home/diego/git/AEPython_2024/data/fmerged_rpoints_attr_sj.shp'\n",
    "points_gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Cargar el archivo ráster multibanda\n",
    "raster_path = 'path_to_your_multiband_raster.tif'\n",
    "raster = mrs #rasterio.open(raster_path)\n",
    "\n",
    "# Crear listas para almacenar los valores de cada banda\n",
    "band_values_lists = {f'b{band_index}': [] for band_index in range(1, raster.count + 1)}\n",
    "\n",
    "# Iterar sobre cada geometría en el shapefile\n",
    "for geom in points_gdf.geometry:\n",
    "    # Lista para almacenar los valores de las bandas para cada punto\n",
    "    band_values = []\n",
    "\n",
    "    if geom.geom_type == 'Point':\n",
    "        # Si es un solo punto, extraer las coordenadas\n",
    "        coords_list = [(geom.x, geom.y)]\n",
    "    elif geom.geom_type == 'MultiPoint':\n",
    "        # Si es MultiPoint, extraer las coordenadas de todos los puntos\n",
    "        coords_list = [(point.x, point.y) for point in geom.geoms]\n",
    "    else:\n",
    "        # Si no es Point ni MultiPoint, continuar con el siguiente\n",
    "        for band_index in range(1, raster.count + 1):\n",
    "            band_values_lists[f'b{band_index}'].append(None)\n",
    "        continue\n",
    "\n",
    "    # Extraer los valores de todas las bandas para cada punto en coords_list\n",
    "    for coords in coords_list:\n",
    "        row, col = raster.index(coords[0], coords[1])\n",
    "        # Extraer los valores de todas las bandas en esa posición\n",
    "        point_band_values = []\n",
    "        for band_index in range(1, raster.count + 1):\n",
    "            band_value = raster.read(band_index)[row, col]\n",
    "            point_band_values.append(band_value)\n",
    "        \n",
    "        # Añadir los valores de las bandas para este punto\n",
    "        band_values.append(point_band_values)\n",
    "\n",
    "    # Calcular el valor medio de todas las bandas si hay puntos válidos, si no asignar None\n",
    "    if band_values:\n",
    "        mean_values = [np.mean(b) for b in zip(*band_values)]  # Calcular el promedio para cada banda\n",
    "        for band_index, mean_value in enumerate(mean_values, start=1):\n",
    "            band_values_lists[f'b{band_index}'].append(int(mean_value))\n",
    "    else:\n",
    "        for band_index in range(1, raster.count + 1):\n",
    "            band_values_lists[f'b{band_index}'].append(None)\n",
    "\n",
    "# Añadir los valores de cada banda al GeoDataFrame\n",
    "for band_index in range(1, raster.count + 1):\n",
    "    points_gdf[f'b{band_index}'] = band_values_lists[f'b{band_index}']\n",
    "\n",
    "# Mostrar los valores obtenidos\n",
    "print(points_gdf[['geometry'] + [f'b{band_index}' for band_index in range(1, raster.count + 1)]])\n",
    "\n",
    "\n",
    "points_gdf.to_file('/home/diego/git/AEPython_2024/data/fmerged_rpoints_attr_sj_multi3.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6197bb-bd5b-4b01-97b3-890bd313cdc3",
   "metadata": {},
   "source": [
    "## Poligonizando rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479b9b7-df0c-4112-9df9-b1d2de09c49b",
   "metadata": {},
   "source": [
    "Vamos a coger el raster que guardamos con las 3 clases de NDVI (4 con el NoData) y vamos a pasarlo a polígonos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d398c-fdae-47e3-bdd0-4b82b5b17afb",
   "metadata": {},
   "source": [
    "### Rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21e82acc-d729-4ee4-9f8e-8b01ccf48512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.7 s ± 321 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Abrir el ráster categórico\n",
    "with rasterio.open('/media/diego/Datos4/EBD/Cursos/AETPython/ndvirec.tif') as src:\n",
    "    raster = src.read(1)  # Leer la primera banda\n",
    "    mask = raster != -9999  # Crear una máscara para los valores no nulos\n",
    "\n",
    "    # Poligonizar el ráster\n",
    "    results = (\n",
    "        {'properties': {'class': v}, 'geometry': shape(s)}\n",
    "        for s, v in shapes(raster, mask=mask, transform=src.transform)\n",
    "    )\n",
    "\n",
    "    # Convertir a GeoDataFrame\n",
    "    geoms = list(results)\n",
    "    gdf = gpd.GeoDataFrame.from_features(geoms, crs=src.crs)\n",
    "\n",
    "# Guardar como shapefile\n",
    "gdf.to_file('/media/diego/Datos4/EBD/Cursos/AETPython/ndvi_pol_.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d63ee-ee34-4cb5-ad3d-01f7a660bd11",
   "metadata": {},
   "source": [
    "## Gdal python bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7399383d-6780-4263-8e2f-bccd82dc2ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 s ± 279 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "from osgeo import gdal, ogr\n",
    "import numpy as np\n",
    "\n",
    "# Abrir el ráster con GDAL\n",
    "raster_ds = gdal.Open('/media/diego/Datos4/EBD/Cursos/AETPython/ndvirec.tif')\n",
    "band = raster_ds.GetRasterBand(1)\n",
    "\n",
    "# Crear el shapefile de salida\n",
    "shapefile = '/media/diego/Datos4/EBD/Cursos/AETPython/ndvi_pol_gdal.shp'\n",
    "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "out_ds = driver.CreateDataSource(shapefile)\n",
    "out_layer = out_ds.CreateLayer('categories', srs=None)\n",
    "\n",
    "# Añadir un campo para la categoría\n",
    "field = ogr.FieldDefn('class', ogr.OFTInteger)\n",
    "out_layer.CreateField(field)\n",
    "\n",
    "# Poligonizar el ráster\n",
    "gdal.Polygonize(band, None, out_layer, 0, [], callback=None)\n",
    "\n",
    "# Cerrar los datasets\n",
    "band = None\n",
    "raster_ds = None\n",
    "out_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988db351-57bb-40a6-bc6e-3b7785a03af1",
   "metadata": {},
   "source": [
    "## Pure GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb057d4-f5b4-46e0-b414-448f1dab63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "2 s ± 201 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "!gdal_polygonize -nomask -overwrite /media/diego/Datos4/EBD/Cursos/AETPython/ndvirec.tif /media/diego/Datos4/EBD/Cursos/AETPython/ndvi_pol_truegdal.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b3c82-86f6-4d4d-998e-17a4770499ff",
   "metadata": {},
   "source": [
    "## Upside down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e60cbf-45c7-4c64-8274-51c132a0df20",
   "metadata": {},
   "source": [
    "## Rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf3dcd-eb24-4729-b24f-3e69115ef2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# Abrir el shapefile con geopandas\n",
    "gdf = gpd.read_file('path/to/polygon.shp')\n",
    "\n",
    "# Definir los parámetros del ráster de salida\n",
    "transform = rasterio.transform.from_origin(0, 0, 100, 100)  # Origen (izquierda, superior), tamaño de píxel (x, y)\n",
    "raster_size = (1000, 1000)  # Tamaño del ráster en píxeles (ancho, alto)\n",
    "\n",
    "# Obtener las geometrías y los valores\n",
    "shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf['class']))\n",
    "\n",
    "# Rasterizar\n",
    "raster = rasterize(\n",
    "    shapes,\n",
    "    out_shape=raster_size,\n",
    "    transform=transform,\n",
    "    fill=0,  # Valor para las celdas vacías\n",
    "    dtype='int32'\n",
    ")\n",
    "\n",
    "# Guardar el ráster de salida\n",
    "with rasterio.open(\n",
    "    'path/to/output_raster.tif',\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=raster_size[0],\n",
    "    width=raster_size[1],\n",
    "    count=1,\n",
    "    dtype=raster.dtype,\n",
    "    crs=gdf.crs,\n",
    "    transform=transform,\n",
    ") as dst:\n",
    "    dst.write(raster, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b72e1-66aa-4992-8cd7-0787722e22b2",
   "metadata": {},
   "source": [
    "## Gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57463c-e263-4908-b127-d00e4e72fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Parámetros del ráster de salida\n",
    "output_raster = 'path/to/output_raster.tif'\n",
    "x_res = 100  # Resolución en el eje X\n",
    "y_res = 100  # Resolución en el eje Y\n",
    "raster_size = (1000, 1000)  # Tamaño del ráster en píxeles (ancho, alto)\n",
    "\n",
    "# Crear el ráster de salida\n",
    "raster_ds = gdal.GetDriverByName('GTiff').Create(output_raster, raster_size[0], raster_size[1], 1, gdal.GDT_Int32)\n",
    "raster_ds.SetGeoTransform((0, x_res, 0, 0, 0, -y_res))  # Define la transformación del ráster (origen y tamaño de los píxeles)\n",
    "\n",
    "# Abrir el shapefile con OGR\n",
    "vector_ds = ogr.Open('path/to/polygon.shp')\n",
    "layer = vector_ds.GetLayer()\n",
    "\n",
    "# Rasterizar la capa vectorial\n",
    "gdal.RasterizeLayer(raster_ds, [1], layer, options=[\"ATTRIBUTE=class\"])  # 'class' es el nombre del campo en el shapefile que quieres rasterizar\n",
    "\n",
    "# Cerrar los datasets\n",
    "raster_ds = None\n",
    "vector_ds = None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
